{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "import PIL\n",
    "TOKENIZER_PATH = 'quant3.onnx'\n",
    "INPUT_SHAPE = (256, 160)\n",
    "WHEEL_SPEEDS_RANGE = [-150, 150]\n",
    "WHEEL_SPEEDS_VOCAB_SIZE = 512\n",
    "WHEEL_SPEED_BINS = np.linspace(WHEEL_SPEEDS_RANGE[0], WHEEL_SPEEDS_RANGE[1], WHEEL_SPEEDS_VOCAB_SIZE)\n",
    "\n",
    "options = ort.SessionOptions()\n",
    "tokenizer_session = ort.InferenceSession(TOKENIZER_PATH, options, ['CUDAExecutionProvider'])\n",
    "pickle_dir = './pickle_data'\n",
    "data_dirs = os.listdir(pickle_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_files = []\n",
    "for dir in data_dirs:\n",
    "    t = len(os.listdir(os.path.join(pickle_dir, dir)))\n",
    "    for it in range(0, t):\n",
    "        obs_files.append(os.path.join(pickle_dir, dir, f'iter_{it}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, target_image_size=256, map_dalle=True):\n",
    "    s = min(img.size)\n",
    "    \n",
    "    if s < target_image_size:\n",
    "        raise ValueError(f'min dim for image {s} < {target_image_size}')\n",
    "        \n",
    "    r = target_image_size / s\n",
    "    s = (round(r * img.size[1]), round(r * img.size[0]))\n",
    "    s = (160, 256)\n",
    "    img = TF.resize(img, s, interpolation=PIL.Image.LANCZOS)\n",
    "    #img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
    "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
    "    #if map_dalle: \n",
    "     # img = map_pixels(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vqgan(x):\n",
    "      x = 2.*x - 1.\n",
    "      return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "  x = x.detach().cpu()\n",
    "  x = torch.clamp(x, -1., 1.)\n",
    "  x = (x + 1.)/2.\n",
    "  x = x.permute(1,2,0).numpy()\n",
    "  x = (255*x).astype(np.uint8)\n",
    "  x = Image.fromarray(x)\n",
    "  if not x.mode == \"RGB\":\n",
    "    x = x.convert(\"RGB\")\n",
    "  return x\n",
    "\n",
    "def reconstruct_with_vqgan(img):\n",
    "  # could also use model(x) for reconstruction but use explicit encoding and decoding here\n",
    "\n",
    "  img_tokens = tokenizer_session.run(None, {'input': np.array(img)})[2]\n",
    "  #print(f\"VQGAN --- {model.__class__.__name__}: latent shape: {z.shape[2:]}\")\n",
    "  #xrec = model.decode(z)\n",
    "  return img_tokens.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_wheel_speed(speed):\n",
    "    speed = np.clip(speed, WHEEL_SPEEDS_RANGE[0], WHEEL_SPEEDS_RANGE[1])\n",
    "    return np.digitize(speed, WHEEL_SPEED_BINS, right=True)\n",
    "def tokenize_frame(image):\n",
    "    image = Image.fromarray(image)\n",
    "    x_vqgan = preprocess(image, target_image_size=256, map_dalle=False)\n",
    "    img_tokens = reconstruct_with_vqgan(preprocess_vqgan(x_vqgan)) \n",
    "    return img_tokens\n",
    "def tokenize_actions(action):\n",
    "    #this is correct don't spend time here lol\n",
    "    ws = action[0]\n",
    "    ad = action[1]\n",
    "    ws = ws + 1\n",
    "    ad = ad + 1\n",
    "    action_index = 3*ad + ws\n",
    "    return np.array(action_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4. 873. 595. ... 596. 256. 256.]\n",
      " [  4. 873. 595. ... 596. 256. 256.]\n",
      " [  4. 873. 595. ... 596. 256. 256.]\n",
      " ...\n",
      " [  4. 873. 595. ... 596. 256. 256.]\n",
      " [  4. 873. 595. ... 596. 256. 256.]\n",
      " [  4. 873. 595. ... 596. 256. 256.]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "token_data = np.zeros((1, 163))\n",
    "for dfile in obs_files:\n",
    "    if(i == 10):\n",
    "        #only 10 for checking now\n",
    "        break\n",
    "    with open(dfile, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        img_tokens = tokenize_frame(data['obs']['cameras']['driver'])\n",
    "        wheel_speeds = data['obs']['carState']['wheelSpeeds']\n",
    "        wheel_speeds = np.array([wheel_speeds[\"fl\"], wheel_speeds[\"fr\"]])\n",
    "        wheel_speeds_tokens = np.expand_dims(tokenize_wheel_speed(wheel_speeds), 0)\n",
    "        action_token = tokenize_actions(data['action']).reshape(-1,1)\n",
    "        #print(action_token)\n",
    "        #print(img_tokens)\n",
    "        #print(wheel_speeds_tokens)\n",
    "        data_row = np.concatenate([action_token ,img_tokens, wheel_speeds_tokens], axis = 1)\n",
    "        token_data = np.concatenate([token_data, data_row], axis = 0)\n",
    "    i = i+1\n",
    "token_data = token_data[1:]\n",
    "print(token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
